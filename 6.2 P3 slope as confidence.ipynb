{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1296fdb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac43f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c0dd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats, ndimage\n",
    "from scipy.stats import pearsonr \n",
    "from itertools import chain, zip_longest\n",
    "from copy import deepcopy\n",
    "import glmtools as glm\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_predict, train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_t_test\n",
    "mne.set_log_level('warning') \n",
    "\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "input_dir = 'TaskstimulusEpochsMastoids'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3803c42b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_subj_eeg(path, file, downsample=None):\n",
    "    fp = os.path.join(path, '%s-epo.fif' % file)\n",
    "    print('>>> Loading %s' % fp)\n",
    "    epochs = mne.read_epochs(fp, preload=True)\n",
    "    if downsample is not None:\n",
    "        epochs = epochs.resample(downsample)\n",
    "    return epochs\n",
    "\n",
    "def load_all_eeg(path, files, downsample=None):\n",
    "    subject_epochs = [load_subj_eeg(path, file, downsample=downsample) for file in files]\n",
    "    epochs = mne.epochs.concatenate_epochs(subject_epochs)\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1925cbea-970b-4934-899b-0a7755bd2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runclustertest_epochs(data, contrast_name, channels, tmin = None, tmax = None, gauss_smoothing = None, out_type = 'indices', n_permutations = 'Default', n_jobs = 1):\n",
    "    '''\n",
    "    func to run cluster permutation tests on voltage data (epochs)\n",
    "    data = data object. dictionary where each key is a contrast name, and inside it is a list (of length nsubs) of Evoked objects\n",
    "    contrast_name = name of the contrast you want to run the test on\n",
    "    channels = list. list of channels you want to average over. if one channel only, obviously no averaging across channels. still needs to be list\n",
    "    tmin, tmax = if you want to restrict permutation tests to a time window, do it here\n",
    "    gauss_smoothing = width (sigma) of a gaussian smoothing that is performed on the single subject data prior to running the test. if None (default) - no smoothing.\n",
    "                      NOTE: the time width of this smoothing depends on your sampling frequency so make sure to use this properly\n",
    "    out_type = specify output type. default to indices, can set to mask if you really want\n",
    "    '''\n",
    "    import scipy as sp\n",
    "    from scipy import ndimage\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    dat       = deepcopy(data[contrast_name])\n",
    "    nsubs     = len(dat)\n",
    "    times    = deepcopy(dat[0]).crop(tmin=tmin, tmax=tmax).times\n",
    "    cludat    = np.empty(shape = (nsubs, 1, times.size)) #specify 1 because we're going to average across channels anyway\n",
    "    \n",
    "    for i in range(nsubs):\n",
    "        tmp = deepcopy(dat[i])\n",
    "        tmp.crop(tmin=tmin, tmax=tmax).pick_channels(channels) #select time window and channels we want\n",
    "        if gauss_smoothing != None:\n",
    "            cludat[i,:,:] = sp.ndimage.gaussian_filter1d(np.nanmean(tmp.data, axis=0), sigma = gauss_smoothing)\n",
    "        else:\n",
    "            cludat[i,:,:] = np.nanmean(tmp.data, axis=0) #average across channels\n",
    "    if n_permutations != 'Default':\n",
    "        t, clusters, cluster_pv, H0 = mne.stats.permutation_cluster_1samp_test(cludat, out_type=out_type, n_permutations = n_permutations, n_jobs = n_jobs)\n",
    "    else:\n",
    "        t, clusters, cluster_pv, H0 = mne.stats.permutation_cluster_1samp_test(cludat, out_type=out_type, n_jobs = n_jobs)\n",
    "    return t, clusters, cluster_pv, H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a69600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nanzscore(vector, zero_out_nans = True):\n",
    "            '''\n",
    "            zscore a vector ignoring nans\n",
    "            optionally can set nans to 0 afterwards. useful for regressors\n",
    "            '''\n",
    "            vector = np.divide(np.subtract(vector, np.nanmean(vector)), np.nanstd(vector))\n",
    "            if zero_out_nans:\n",
    "                vector = np.where(np.isnan(vector), 0, vector)\n",
    "            \n",
    "            return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21c12d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "participant_numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21] # 14 was excluded due to noise\n",
    "\n",
    "sessions = [1, 2]\n",
    "\n",
    "partners = ['\"overconfident\"', '\"underconfident\"']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b55e8-7662-4ea7-8add-e808f88b72e0",
   "metadata": {},
   "source": [
    "# Regress voltage on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c880e52-e13c-470e-84c9-2d14e1a2acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for every trial, regress voltage against timepoint\n",
    "## get a beta for every trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87f222bb-b7f4-4223-ac91-ec80e508913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading TaskstimulusEpochsMastoids/3_1-epo.fif\n",
      ">>> Loading TaskstimulusEpochsMastoids/3_2-epo.fif\n",
      "Pz\n",
      "(0.05471444248316028, 0.18482146594878396)\n",
      "(0.04556943614028139, 0.2695221715203272)\n",
      "CPz\n",
      "(0.0555462690895719, 0.178223168690332)\n",
      "(0.035983665687658, 0.38335768587762203)\n",
      "POz\n",
      "(0.05547685864250326, 0.17876697460367807)\n",
      "(0.06011844897403891, 0.14504659759319932)\n",
      "P1\n",
      "(0.05800306032059598, 0.15975727315115815)\n",
      "(0.049186219485774806, 0.23329972230097284)\n",
      "P2\n",
      "(0.05289978394821936, 0.19983830807451453)\n",
      "(0.046525280210824874, 0.2595949911973805)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "roi = [\"Pz\", \"CPz\", \"POz\", \"P1\", \"P2\"]\n",
    "\n",
    "#for sub in participant_numbers:\n",
    "for sub in [3]:\n",
    "    participant_files = []\n",
    "    for session in sessions:\n",
    "        participant_files.append('%i_%i' % (sub, session))\n",
    "    epochs = load_all_eeg(path='%s/' % input_dir, files=participant_files)\n",
    "    \n",
    "    # participant confidence on each trial\n",
    "    confidence = epochs.metadata['participant_confidence'].to_numpy() \n",
    "    \n",
    "    # indices of roi channels to perform the regressions on\n",
    "    channel_indices = []\n",
    "    for channel in roi:\n",
    "        channel_index = mne.pick_channels(info['ch_names'], [channel])\n",
    "        channel_indices.append(channel_index[0])\n",
    "    \n",
    "    # crop epochs to time window of interest\n",
    "    epoch_start = 0.2\n",
    "    epoch_end = 0.6\n",
    "    epochs = epochs.crop(tmin=epoch_start, tmax=epoch_end, include_tmax=True)\n",
    "    \n",
    "    # dependent variable is voltage\n",
    "    data = epochs.get_data()\n",
    "    ntrials, nchannels, ntimes = data.shape\n",
    "    \n",
    "    # regressor is time\n",
    "    timepoint = np.array(range(ntimes))\n",
    "    x = timepoint.reshape(-1, 1)\n",
    "\n",
    "    timepoint_betas = np.zeros([nchannels, ntrials]) *np.nan\n",
    "    timepoint_correlations = np.zeros([nchannels, ntrials]) *np.nan\n",
    "\n",
    "    a = -1\n",
    "    for channel in channel_indices:\n",
    "        a = a+1\n",
    "        data_channel = data[:, channel, :]\n",
    "        \n",
    "        for trial in range(ntrials):\n",
    "            y = data_channel[trial, :]\n",
    "        \n",
    "            # creating an object of LinearRegression class\n",
    "            LR = LinearRegression()\n",
    "            # fitting the model --> for every channel, for every trial, we regress voltage against time\n",
    "            LR.fit(x,y)            \n",
    "            betas = LR.coef_\n",
    "            \n",
    "            timepoint_betas[channel, trial] = betas[0]\n",
    "            timepoint_correlations[channel, trial] = sp.stats.pearsonr(timepoint, y)[0]\n",
    "        \n",
    "        #print(np.mean(timepoint_betas[channel, :]))\n",
    "        #print(np.mean(timepoint_correlations[channel, :]))\n",
    "        \n",
    "        # correlation of beta with confidence\n",
    "        print(roi[a])\n",
    "        print(sp.stats.pearsonr(timepoint_betas[channel, :], confidence))\n",
    "        print(sp.stats.pearsonr(timepoint_correlations[channel, :], confidence))\n",
    "       \n",
    "    #np.save(file='/Users/majaf/Desktop/Google Drive/PhD/Study 5 Confidence Matching with EEG (A)/Data Analysis/TimepointBetas/slope_%i.npy' % sub, arr=timepoint_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71af27e8-3af9-4b90-9cd3-a78913eca1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.04268836e-06,  8.92784010e-06,  8.73439785e-06,  8.18530680e-06,\n",
       "        7.15981878e-06,  5.77574747e-06,  4.37843664e-06,  3.42652993e-06,\n",
       "        3.30112243e-06,  4.10927032e-06,  5.58237934e-06,  7.15020724e-06,\n",
       "        8.18938406e-06,  8.33788727e-06,  7.70489896e-06,  6.84256611e-06,\n",
       "        6.47272327e-06,  7.10524364e-06,  8.75702881e-06,  1.09338907e-05,\n",
       "        1.28938682e-05,  1.40490829e-05,  1.42771187e-05,  1.39573867e-05,\n",
       "        1.37056659e-05,  1.39636268e-05,  1.46970524e-05,  1.53986130e-05,\n",
       "        1.54056015e-05,  1.43432444e-05,  1.24180660e-05,  1.03702541e-05,\n",
       "        9.09785467e-06,  9.16439421e-06,  1.04767141e-05,  1.23267509e-05,\n",
       "        1.37822844e-05,  1.42068311e-05,  1.36090939e-05,  1.26184905e-05,\n",
       "        1.21013554e-05,  1.26421091e-05,  1.41894034e-05,  1.60664549e-05,\n",
       "        1.73318658e-05,  1.72797500e-05,  1.57982249e-05,  1.33975700e-05,\n",
       "        1.09141311e-05,  9.07746107e-06,  8.19173965e-06,  8.09608991e-06,\n",
       "        8.39014137e-06,  8.75321075e-06,  9.14357679e-06,  9.75890180e-06,\n",
       "        1.08039912e-05,  1.22393731e-05,  1.36935641e-05,  1.46115353e-05,\n",
       "        1.45555587e-05,  1.34718057e-05,  1.17497011e-05,  1.00228899e-05,\n",
       "        8.81834058e-06,  8.25920506e-06,  8.00459202e-06,  7.47332660e-06,\n",
       "        6.22802509e-06,  4.29470765e-06,  2.22515428e-06,  8.55622545e-07,\n",
       "        8.88851844e-07,  2.52618588e-06,  5.34849505e-06,  8.50661854e-06,\n",
       "        1.11120717e-05,  1.26119457e-05,  1.29490254e-05,  1.24395665e-05,\n",
       "        1.14690965e-05,  1.02099975e-05,  8.54163591e-06,  6.22024163e-06,\n",
       "        3.18469984e-06, -2.06534537e-07, -3.17926106e-06, -4.82287351e-06,\n",
       "       -4.51732421e-06, -2.28387080e-06,  1.13781005e-06,  4.54565861e-06,\n",
       "        6.74861667e-06,  7.02724583e-06,  5.36416474e-06,  2.35763719e-06,\n",
       "       -1.10003032e-06, -4.19152457e-06, -6.41378165e-06, -7.61584397e-06,\n",
       "       -7.88869329e-06])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccca1cc-6b30-45d7-9a80-aca5cf58dec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
